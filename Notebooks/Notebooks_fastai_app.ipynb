{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook loads in the model that was trained in my 'DL_categorical-fastai' notebook. I have created a 'predictor' function which will make predictions of the number of likes that your comment will receive based on the text provided, and show examples of calling this function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and then load my model. \n",
    "#Because the cuDNN libraries tend to fail to load the first time, I have the code try again on an exception error to make it work the second time.\n",
    "\n",
    "from fastai.text import *\n",
    "from fastai.basics import *\n",
    "try:    \n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set thi\n",
    "\n",
    "    path = \"models/\"\n",
    "    learn = load_learner(path, 'balanced_50k.pkl')\n",
    "except:\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set thi\n",
    "\n",
    "    path = \"models/\"\n",
    "    learn = load_learner(path, 'balanced_50k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take a comment and make a prediction based on the content.\n",
    "\n",
    "def predictor(test_comment):\n",
    " \n",
    "    cat, tensor, probs = learn.predict(test_comment)\n",
    "    \n",
    "    #cat = np.argmax(tensor)\n",
    "    \n",
    "    category = str(cat)\n",
    "    print(category, probs)\n",
    "    if category == '0': print('This comment is predicted to be unpopular and receive no likes.') \n",
    "    else: print('This comment is predicted to be popular and receive some likes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Local\\Continuum\\anaconda3_reinstall\\envs\\fastai_v1\\lib\\site-packages\\fastai\\torch_core.py:83: UserWarning: Tensor is int32: upgrading to int64; for better performance use int64 input\n",
      "  warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.6150, 0.3850])\n",
      "This comment is predicted to be unpopular and receive no likes.\n"
     ]
    }
   ],
   "source": [
    "predictor(\"ASAPD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Local\\Continuum\\anaconda3_reinstall\\envs\\fastai_v1\\lib\\site-packages\\fastai\\torch_core.py:83: UserWarning: Tensor is int32: upgrading to int64; for better performance use int64 input\n",
      "  warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([0.4399, 0.5601])\n",
      "This comment is predicted to be popular and receive some likes.\n"
     ]
    }
   ],
   "source": [
    "string = \"What is the worth of a man these days\"\n",
    "predictor(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Local\\Continuum\\anaconda3_reinstall\\envs\\fastai_v1\\lib\\site-packages\\fastai\\torch_core.py:83: UserWarning: Tensor is int32: upgrading to int64; for better performance use int64 input\n",
      "  warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.8979, 0.1021])\n",
      "This comment is predicted to be unpopular and receive no likes.\n",
      "\n",
      "\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Continuum\\anaconda3_reinstall\\envs\\fastai_v1\\lib\\site-packages\\ipykernel_launcher.py\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Local\\Continuum\\anaconda3_reinstall\\envs\\fastai_v1\\lib\\site-packages\\fastai\\torch_core.py:83: UserWarning: Tensor is int32: upgrading to int64; for better performance use int64 input\n",
      "  warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.6158, 0.3842])\n",
      "This comment is predicted to be unpopular and receive no likes.\n",
      "\n",
      "\n",
      "-f\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Local\\Continuum\\anaconda3_reinstall\\envs\\fastai_v1\\lib\\site-packages\\fastai\\torch_core.py:83: UserWarning: Tensor is int32: upgrading to int64; for better performance use int64 input\n",
      "  warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.8718, 0.1282])\n",
      "This comment is predicted to be unpopular and receive no likes.\n",
      "\n",
      "\n",
      "C:\\Users\\msteele9\\AppData\\Roaming\\jupyter\\runtime\\kernel-570d71eb-0621-420e-a19f-1d9efd50e578.json\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(sys.argv) > 0:\n",
    "    for arg in sys.argv:\n",
    "        string = arg\n",
    "        rec = predictor(string)\n",
    "        print(\"\\n\")\n",
    "        print(string)\n",
    "        print(rec)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai_v1] *",
   "language": "python",
   "name": "conda-env-fastai_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
